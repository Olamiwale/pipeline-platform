# DAY 6: Advanced Features & Performance Testing
# Load testing, chaos engineering, auto-scaling optimization

---
# Load Testing with K6
apiVersion: v1
kind: ConfigMap
metadata:
  name: k6-scripts
  namespace: cicd
data:
  load-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    export const options = {
      stages: [
        { duration: '2m', target: 10 },   // Ramp up
        { duration: '5m', target: 50 },   // Stay at 50 users
        { duration: '2m', target: 100 },  // Spike
        { duration: '5m', target: 50 },   // Scale down
        { duration: '2m', target: 0 },    // Ramp down
      ],
      thresholds: {
        http_req_duration: ['p(95)<500'],  // 95% requests under 500ms
        http_req_failed: ['rate<0.01'],    // Error rate under 1%
      },
    };
    
    export default function () {
      const res = http.get('http://sample-app.dev');
      
      check(res, {
        'status is 200': (r) => r.status === 200,
        'response time OK': (r) => r.timings.duration < 500,
      });
      
      sleep(1);
    }
  
  stress-test.js: |
    import http from 'k6/http';
    import { check } from 'k6';
    
    export const options = {
      stages: [
        { duration: '2m', target: 100 },
        { duration: '5m', target: 100 },
        { duration: '2m', target: 200 },
        { duration: '5m', target: 200 },
        { duration: '2m', target: 300 },
        { duration: '5m', target: 300 },
        { duration: '10m', target: 0 },
      ],
    };
    
    export default function () {
      const res = http.get('http://sample-app.dev');
      check(res, { 'status is 200': (r) => r.status === 200 });
    }
  
  build-load-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    export const options = {
      vus: 50,
      duration: '10m',
    };
    
    export default function () {
      // Simulate triggering 50 parallel builds
      const payload = JSON.stringify({
        ref: 'main',
        inputs: {
          test: 'true'
        }
      });
      
      const params = {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': 'token ${__ENV.GITHUB_TOKEN}',
        },
      };
      
      const res = http.post(
        'https://api.github.com/repos/your-org/your-repo/actions/workflows/build.yml/dispatches',
        payload,
        params
      );
      
      check(res, {
        'workflow triggered': (r) => r.status === 204,
      });
      
      sleep(10);
    }

---
# K6 Job for load testing
apiVersion: batch/v1
kind: Job
metadata:
  name: load-test
  namespace: cicd
spec:
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      containers:
      - name: k6
        image: grafana/k6:latest
        command:
        - k6
        - run
        - --out
        - influxdb=http://influxdb.monitoring:8086/k6
        - /scripts/load-test.js
        
        volumeMounts:
        - name: k6-scripts
          mountPath: /scripts
        
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "2000m"
            memory: "2Gi"
      
      volumes:
      - name: k6-scripts
        configMap:
          name: k6-scripts
      
      restartPolicy: Never

---
# GitHub Actions Load Test Workflow
apiVersion: v1
kind: ConfigMap
metadata:
  name: load-test-workflow
  namespace: cicd
data:
  load-test.yml: |
    name: Load Test
    
    on:
      workflow_dispatch:
        inputs:
          target_url:
            description: 'Target URL to test'
            required: true
            default: 'http://sample-app.dev'
          duration:
            description: 'Test duration (e.g., 5m, 10m)'
            required: true
            default: '5m'
          vus:
            description: 'Virtual users'
            required: true
            default: '50'
    
    jobs:
      load-test:
        runs-on: [self-hosted, kubernetes]
        steps:
        - uses: actions/checkout@v3
        
        - name: Run K6 load test
          run: |
            kubectl create job load-test-${{ github.run_number }} \
              --from=job/load-test \
              --dry-run=client -o yaml | \
            kubectl apply -f -
        
        - name: Wait for test completion
          run: |
            kubectl wait --for=condition=complete \
              job/load-test-${{ github.run_number }} \
              --timeout=30m \
              -n cicd
        
        - name: Get test results
          run: |
            kubectl logs job/load-test-${{ github.run_number }} -n cicd
        
        - name: Cleanup
          if: always()
          run: |
            kubectl delete job load-test-${{ github.run_number }} -n cicd

---
# Chaos Engineering with Chaos Mesh
# Install: curl -sSL https://mirrors.chaos-mesh.org/latest/install.sh | bash

---
# Pod Chaos - Random pod deletion
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-failure
  namespace: cicd
spec:
  action: pod-failure
  mode: one
  duration: "30s"
  selector:
    namespaces:
      - dev
    labelSelectors:
      app: sample-app
  scheduler:
    cron: "@every 1h"

---
# Network Chaos - Introduce latency
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay
  namespace: cicd
spec:
  action: delay
  mode: one
  selector:
    namespaces:
      - dev
    labelSelectors:
      app: sample-app
  delay:
    latency: "100ms"
    correlation: "100"
    jitter: "0ms"
  duration: "5m"
  scheduler:
    cron: "@every 2h"

---
# Stress Chaos - CPU/Memory stress
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: burn-cpu
  namespace: cicd
spec:
  mode: one
  selector:
    namespaces:
      - staging
    labelSelectors:
      app: sample-app
  stressors:
    cpu:
      workers: 2
      load: 50
  duration: "2m"

---
# GitHub Actions Chaos Test Workflow
apiVersion: v1
kind: ConfigMap
metadata:
  name: chaos-workflow
  namespace: cicd
data:
  chaos-test.yml: |
    name: Chaos Engineering Test
    
    on:
      schedule:
        - cron: '0 10 * * 1'  # Every Monday at 10 AM
      workflow_dispatch:
    
    jobs:
      chaos-test:
        runs-on: [self-hosted, kubernetes]
        steps:
        - name: Apply pod chaos
          run: |
            kubectl apply -f - <<EOF
            apiVersion: chaos-mesh.org/v1alpha1
            kind: PodChaos
            metadata:
              name: test-pod-kill
              namespace: dev
            spec:
              action: pod-kill
              mode: one
              selector:
                namespaces: [dev]
                labelSelectors:
                  app: sample-app
              duration: "30s"
            EOF
        
        - name: Monitor application health
          run: |
            sleep 10
            for i in {1..30}; do
              STATUS=$(kubectl get pods -n dev -l app=sample-app -o jsonpath='{.items[*].status.phase}')
              echo "Attempt $i: Pod status - $STATUS"
              if [[ "$STATUS" == *"Running"* ]]; then
                echo "âœ“ Application recovered"
                break
              fi
              sleep 10
            done
        
        - name: Check metrics
          run: |
            # Query Prometheus for error rate during chaos
            curl -G http://prometheus.monitoring:9090/api/v1/query \
              --data-urlencode 'query=rate(http_requests_total{status=~"5.*"}[5m])'
        
        - name: Cleanup chaos
          if: always()
          run: |
            kubectl delete podchaos test-pod-kill -n dev

---
# HPA Optimization Testing
apiVersion: v1
kind: ConfigMap
metadata:
  name: hpa-test
  namespace: cicd
data:
  test-hpa.sh: |
    #!/bin/bash
    
    # Test HPA behavior under different loads
    
    echo "=== Testing HPA Scaling ==="
    
    # Initial state
    echo "Initial replicas:"
    kubectl get hpa -n dev
    
    # Generate load
    echo "Generating load..."
    kubectl run load-generator \
      --image=busybox \
      --restart=Never \
      -- /bin/sh -c "while true; do wget -q -O- http://sample-app.dev; done"
    
    # Monitor scaling
    for i in {1..20}; do
      echo "=== Minute $i ==="
      kubectl get hpa -n dev
      kubectl top pods -n dev
      sleep 60
    done
    
    # Stop load
    kubectl delete pod load-generator
    
    # Monitor scale down
    echo "=== Monitoring scale down ==="
    for i in {1..10}; do
      echo "Minute $i after load stopped:"
      kubectl get hpa -n dev
      sleep 60
    done

---
# Performance benchmark Job
apiVersion: batch/v1
kind: Job
metadata:
  name: benchmark
  namespace: cicd
spec:
  template:
    spec:
      containers:
      - name: benchmark
        image: williamyeh/wrk:latest
        command:
        - wrk
        - -t12
        - -c400
        - -d30s
        - --latency
        - http://sample-app.dev
        
        resources:
          requests:
            cpu: "1000m"
            memory: "1Gi"
          limits:
            cpu: "2000m"
            memory: "2Gi"
      
      restartPolicy: Never

---
# Build cache performance test
apiVersion: v1
kind: ConfigMap
metadata:
  name: cache-test-workflow
  namespace: cicd
data:
  cache-test.yml: |
    name: Cache Performance Test
    
    on:
      workflow_dispatch:
    
    jobs:
      test-no-cache:
        runs-on: [self-hosted, kubernetes]
        steps:
        - uses: actions/checkout@v3
        
        - name: Build without cache
          run: |
            START=$(date +%s)
            docker build --no-cache -t test:no-cache .
            END=$(date +%s)
            echo "Build time without cache: $((END - START))s"
      
      test-with-cache:
        runs-on: [self-hosted, kubernetes]
        steps:
        - uses: actions/checkout@v3
        
        - name: Build with cache
          uses: docker/build-push-action@v4
          with:
            context: .
            tags: test:cached
            cache-from: type=registry,ref=registry.local:5000/app:buildcache
            cache-to: type=registry,ref=registry.local:5000/app:buildcache,mode=max
        
        - name: Compare results
          run: |
            echo "Cache hit rate and time saved reported in metrics"

---
# Resource optimization
apiVersion: v1
kind: ConfigMap
metadata:
  name: optimize-resources
  namespace: cicd
data:
  analyze.sh: |
    #!/bin/bash
    
    echo "=== Resource Usage Analysis ==="
    
    # Get actual vs requested resources
    kubectl top pods -n dev
    kubectl get pods -n dev -o json | jq -r '
      .items[] | 
      "\(.metadata.name),\(.spec.containers[0].resources.requests.cpu),\(.spec.containers[0].resources.requests.memory)"
    '
    
    # Recommendations
    echo "=== Optimization Recommendations ==="
    kubectl-resource-recommendation -n dev

---
# PodDisruptionBudget for testing
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: sample-app-pdb
  namespace: dev
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: sample-app

---
# Priority Classes for build jobs
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority-build
value: 1000
globalDefault: false
description: "High priority for urgent builds"

---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: low-priority-build
value: 100
globalDefault: false
description: "Low priority for non-urgent builds"

---
# Updated runner deployment with priority
apiVersion: apps/v1
kind: Deployment
metadata:
  name: priority-runner
  namespace: cicd
spec:
  replicas: 2
  selector:
    matchLabels:
      app: priority-runner
  template:
    metadata:
      labels:
        app: priority-runner
    spec:
      priorityClassName: high-priority-build
      # ... rest of runner spec