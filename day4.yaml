# DAY 4: Security & RBAC
# Image scanning, secret management, RBAC, Pod Security

---
# ServiceAccounts for different roles
apiVersion: v1
kind: ServiceAccount
metadata:
  name: github-runner-sa
  namespace: cicd

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: developer-sa
  namespace: dev

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: deployer-sa
  namespace: prod

---
# RBAC: CI/CD Role (can deploy to dev/staging)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: cicd-deployer
  namespace: dev
rules:
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets", "statefulsets"]
  verbs: ["get", "list", "create", "update", "patch", "delete"]
- apiGroups: [""]
  resources: ["pods", "services", "configmaps", "secrets"]
  verbs: ["get", "list", "create", "update", "patch", "delete"]
- apiGroups: ["batch"]
  resources: ["jobs", "cronjobs"]
  verbs: ["get", "list", "create", "update", "patch", "delete"]
- apiGroups: ["networking.k8s.io"]
  resources: ["ingresses"]
  verbs: ["get", "list", "create", "update", "patch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: github-runner-deployer
  namespace: dev
subjects:
- kind: ServiceAccount
  name: github-runner-sa
  namespace: cicd
roleRef:
  kind: Role
  name: cicd-deployer
  apiGroup: rbac.authorization.k8s.io

---
# RBAC: Read-only for developers
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: developer-readonly
  namespace: prod
rules:
- apiGroups: [""]
  resources: ["pods", "pods/log", "services", "configmaps"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets", "statefulsets"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: developers-readonly-prod
  namespace: prod
subjects:
- kind: Group
  name: developers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: developer-readonly
  apiGroup: rbac.authorization.k8s.io

---
# RBAC: Production deployer (limited)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: prod-deployer
  namespace: prod
rules:
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "patch"]  # Only patch for image updates
  resourceNames: ["prod-sample-app"]  # Specific deployment only
- apiGroups: [""]
  resources: ["pods", "pods/log"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: deployer-prod
  namespace: prod
subjects:
- kind: ServiceAccount
  name: deployer-sa
  namespace: prod
roleRef:
  kind: Role
  name: prod-deployer
  apiGroup: rbac.authorization.k8s.io

---
# Sealed Secrets for GitOps
# Install: kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.24.0/controller.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: sealed-secrets-guide
  namespace: cicd
data:
  usage.md: |
    # Sealed Secrets Usage
    
    ## Install kubeseal CLI
    ```bash
    wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.24.0/kubeseal-0.24.0-linux-amd64.tar.gz
    tar -xvzf kubeseal-0.24.0-linux-amd64.tar.gz
    sudo install -m 755 kubeseal /usr/local/bin/kubeseal
    ```
    
    ## Create sealed secret
    ```bash
    # Create regular secret
    kubectl create secret generic my-secret \
      --from-literal=password=supersecret \
      --dry-run=client -o yaml > secret.yaml
    
    # Seal it
    kubeseal --format yaml < secret.yaml > sealed-secret.yaml
    
    # Commit sealed-secret.yaml to Git (safe to commit!)
    # Apply to cluster
    kubectl apply -f sealed-secret.yaml
    ```

---
# Example Sealed Secret (encrypted)
apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: registry-credentials
  namespace: cicd
spec:
  encryptedData:
    username: AgCQj8H7k...  # Encrypted value
    password: AgBvR9mN2...  # Encrypted value
  template:
    metadata:
      name: registry-credentials
      namespace: cicd
    type: kubernetes.io/dockerconfigjson

---
# Trivy Security Scanner Job
apiVersion: batch/v1
kind: CronJob
metadata:
  name: image-security-scan
  namespace: cicd
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: github-runner-sa
          containers:
          - name: trivy
            image: aquasec/trivy:latest
            command:
            - /bin/sh
            - -c
            - |
              # Scan all images in registry
              IMAGES=$(curl -s http://docker-registry:5000/v2/_catalog | jq -r '.repositories[]')
              
              for IMAGE in $IMAGES; do
                echo "Scanning $IMAGE..."
                trivy image --severity HIGH,CRITICAL \
                  --exit-code 1 \
                  --no-progress \
                  registry.local:5000/$IMAGE:latest || echo "Vulnerabilities found in $IMAGE"
              done
            
            env:
            - name: TRIVY_INSECURE
              value: "true"
            
            resources:
              requests:
                cpu: "500m"
                memory: "512Mi"
              limits:
                cpu: "1000m"
                memory: "1Gi"
          
          restartPolicy: OnFailure

---
# GitHub Actions Security Workflow
apiVersion: v1
kind: ConfigMap
metadata:
  name: security-workflows
  namespace: cicd
data:
  security-scan.yml: |
    name: Security Scan
    
    on:
      push:
        branches: [ main, develop ]
      pull_request:
        branches: [ main ]
      schedule:
        - cron: '0 0 * * *'  # Daily
    
    jobs:
      secret-scan:
        runs-on: [self-hosted, kubernetes]
        steps:
        - uses: actions/checkout@v3
          with:
            fetch-depth: 0
        
        - name: TruffleHog Secret Scan
          uses: trufflesecurity/trufflehog@main
          with:
            path: ./
            base: ${{ github.event.repository.default_branch }}
            head: HEAD
      
      sast:
        runs-on: [self-hosted, kubernetes]
        steps:
        - uses: actions/checkout@v3
        
        - name: Run Semgrep
          uses: returntocorp/semgrep-action@v1
          with:
            config: auto
      
      dependency-check:
        runs-on: [self-hosted, kubernetes]
        steps:
        - uses: actions/checkout@v3
        
        - name: OWASP Dependency Check
          uses: dependency-check/Dependency-Check_Action@main
          with:
            project: 'sample-app'
            path: '.'
            format: 'HTML'
        
        - name: Upload results
          uses: actions/upload-artifact@v3
          with:
            name: dependency-check-report
            path: reports/
      
      container-scan:
        runs-on: [self-hosted, kubernetes]
        needs: build
        steps:
        - name: Run Trivy
          uses: aquasecurity/trivy-action@master
          with:
            image-ref: registry.local:5000/sample-app:${{ github.sha }}
            format: 'sarif'
            output: 'trivy-results.sarif'
            severity: 'CRITICAL,HIGH'
            exit-code: '1'
        
        - name: Upload to GitHub Security
          uses: github/codeql-action/upload-sarif@v2
          with:
            sarif_file: 'trivy-results.sarif'
      
      k8s-manifest-scan:
        runs-on: [self-hosted, kubernetes]
        steps:
        - uses: actions/checkout@v3
        
        - name: Scan Kubernetes manifests
          uses: aquasecurity/trivy-action@master
          with:
            scan-type: 'config'
            scan-ref: './k8s'
            format: 'sarif'
            output: 'k8s-scan-results.sarif'
            exit-code: '1'
        
        - name: Upload results
          uses: github/codeql-action/upload-sarif@v2
          with:
            sarif_file: 'k8s-scan-results.sarif'

---
# Pod Security Standards
apiVersion: v1
kind: Namespace
metadata:
  name: secure-workloads
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/enforce-version: latest
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/audit-version: latest
    pod-security.kubernetes.io/warn: restricted
    pod-security.kubernetes.io/warn-version: latest

---
# Secure Pod Template
apiVersion: v1
kind: Pod
metadata:
  name: secure-app
  namespace: secure-workloads
spec:
  serviceAccountName: developer-sa
  automountServiceAccountToken: false
  
  securityContext:
    runAsNonRoot: true
    runAsUser: 10000
    runAsGroup: 10000
    fsGroup: 10000
    seccompProfile:
      type: RuntimeDefault
  
  containers:
  - name: app
    image: nginx:latest
    
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 10000
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
      seccompProfile:
        type: RuntimeDefault
    
    ports:
    - containerPort: 8080
    
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: cache
      mountPath: /var/cache
    
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
  
  volumes:
  - name: tmp
    emptyDir: {}
  - name: cache
    emptyDir: {}

---
# Network Policies
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
  namespace: prod
spec:
  podSelector: {}
  policyTypes:
  - Ingress

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-ingress
  namespace: prod
spec:
  podSelector:
    matchLabels:
      role: frontend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-to-backend
  namespace: prod
spec:
  podSelector:
    matchLabels:
      role: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 8080

---
# OPA Gatekeeper for Policy Enforcement
# Install: kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml

# Constraint Template: Require labels
apiVersion: templates.gatekeeper.sh/v1
kind: ConstraintTemplate
metadata:
  name: k8srequiredlabels
spec:
  crd:
    spec:
      names:
        kind: K8sRequiredLabels
      validation:
        openAPIV3Schema:
          type: object
          properties:
            labels:
              type: array
              items:
                type: string
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package k8srequiredlabels
        
        violation[{"msg": msg, "details": {"missing_labels": missing}}] {
          provided := {label | input.review.object.metadata.labels[label]}
          required := {label | label := input.parameters.labels[_]}
          missing := required - provided
          count(missing) > 0
          msg := sprintf("Missing required labels: %v", [missing])
        }

---
# Apply constraint
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredLabels
metadata:
  name: require-app-labels
spec:
  match:
    kinds:
      - apiGroups: ["apps"]
        kinds: ["Deployment"]
    namespaces:
      - prod
  parameters:
    labels:
      - "app"
      - "environment"
      - "team"

---
# Audit logging
apiVersion: v1
kind: ConfigMap
metadata:
  name: audit-policy
  namespace: kube-system
data:
  audit-policy.yaml: |
    apiVersion: audit.k8s.io/v1
    kind: Policy
    rules:
    # Log all requests at Metadata level
    - level: Metadata
      omitStages:
      - RequestReceived
    
    # Log pod changes at Request level
    - level: Request
      resources:
      - group: ""
        resources: ["pods"]
      verbs: ["create", "update", "patch", "delete"]
    
    # Log secret access
    - level: Metadata
      resources:
      - group: ""
        resources: ["secrets"]
      verbs: ["get", "list", "watch"]